{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Iceberg Catalog Setup\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Running\")\n",
    "print(spark.sparkContext.getConf().getAll())\n",
    "print(\"current catalog:\", spark.catalog.currentCatalog())\n",
    "print(\"In-heap memory usage:\", spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2_emissions_2017 = spark.read.table(\"raw.co2_passenger_cars_emissions.co2_emissions_passenger_cars_2017\")\n",
    "df_co2_emissions_2018 = spark.read.table(\"raw.co2_passenger_cars_emissions.co2_emissions_passenger_cars_2018\")\n",
    "df_co2_emissions_2019 = spark.read.table(\"raw.co2_passenger_cars_emissions.co2_emissions_passenger_cars_2019\")\n",
    "\n",
    "combined_co2_emissions_df = df_co2_emissions_2017.unionByName(df_co2_emissions_2018).unionByName(df_co2_emissions_2019)\n",
    "\n",
    "combined_co2_emissions_df.printSchema()\n",
    "combined_co2_emissions_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces in column names with underscores (“_”). Additionally, remove parentheses from column names.\n",
    "import re\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "co2_emissions_columns = combined_co2_emissions_df.columns\n",
    "print(f\"Original Column names:: {combined_co2_emissions_df.columns}\")\n",
    "\n",
    "combined_co2_emissions_df = (combined_co2_emissions_df.select(\n",
    "                      [F.col(col).alias(re.sub('[()]', '', col.replace(' ', '_'))) for col in combined_co2_emissions_df.columns]\n",
    "                    ))\n",
    "\n",
    "\n",
    "print(f\"Updated Column names:: {combined_co2_emissions_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records that only consist of null values (records with null values on all columns).\n",
    "print(f\"Record count prior to dropping null values:: {combined_co2_emissions_df.count()}\")\n",
    "combined_co2_emissions_df = combined_co2_emissions_df.dropna(how=\"all\")\n",
    "print(f\"Record count after to dropping null values:: {combined_co2_emissions_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate records.\n",
    "\n",
    "print(f\"Record count prior to dropping duplicate values:: {combined_co2_emissions_df.count()}\")\n",
    "combined_co2_emissions_df = combined_co2_emissions_df.dropDuplicates()\n",
    "print(f\"Record count after to dropping duplicate values:: {combined_co2_emissions_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all records that have a member state code size other than two (column: MS) and that contain any character other than uppercase letters in this column\n",
    "\n",
    "print(f\"Record count prior to filtered state code:: {combined_co2_emissions_df.count()}\")\n",
    "combined_co2_emissions_df = combined_co2_emissions_df.filter(combined_co2_emissions_df['MS'].rlike('^[A-Z][A-Z]$'))\n",
    "print(f\"Record count with filtered state code:: {combined_co2_emissions_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(combined_co2_emissions_df\n",
    ".repartition(\"year\")\n",
    ".writeTo(\"curated.co2_passenger_cars_emissions\")\n",
    ".partitionedBy(\"year\")\n",
    ".options(format=\"iceberg\", mode=\"overwrite\")\n",
    ".createOrReplace()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
