{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Iceberg Catalog Setup\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg.catalog-impl\", \"org.apache.iceberg.rest.RESTCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg.uri\", \"http://iceberg-rest:8181\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg.warehouse\", \"warehouse\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg.s3.access-key\", \"admin\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg.s3.secret-key\", \"password\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg.s3.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg.s3.path-style-access\", \"true\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg.client.factory\", \"com.starrocks.connector.iceberg.IcebergAwsClientFactory\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Running\")\n",
    "print(spark.sparkContext.getConf().getAll())\n",
    "print(\"current catalog:\", spark.catalog.currentCatalog())\n",
    "print(\"Spark UI:\", spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_data_df = spark.read.table(\"raw.world_development_indicators.WDIData\")\n",
    "wdi_country_df = spark.read.table(\"raw.world_development_indicators.WDICountry\")\n",
    "wdi_series_df = spark.read.table(\"raw.world_development_indicators.WDISeries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of records for wdi data DF: {wdi_data_df.count()}\")\n",
    "print(f\"Number of records for wdi country DF: {wdi_country_df.count()}\")\n",
    "print(f\"Number of records for wdi series DF: {wdi_series_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces in column names with underscores (“_”) for all DataFrames.\n",
    "\n",
    "# wdi_data \n",
    "wdi_data_columns = wdi_data_df.columns\n",
    "\n",
    "for column in wdi_data_columns:\n",
    "  if column.__contains__(\" \"):\n",
    "    new_column_name = column.replace(\" \", \"_\")\n",
    "    wdi_data_df = wdi_data_df.withColumnRenamed(column, new_column_name)\n",
    "\n",
    "print(f\"Updated Column names:: {wdi_data_df.columns}\")\n",
    "\n",
    "\n",
    "# wdi_country\n",
    "wdi_country_columns = wdi_country_df.columns\n",
    "\n",
    "for column in wdi_country_columns:\n",
    "  if column.__contains__(\" \"):\n",
    "    new_column_name = column.replace(\" \", \"_\")\n",
    "    wdi_country_df = wdi_country_df.withColumnRenamed(column, new_column_name)\n",
    "\n",
    "print(f\"Updated Column names:: {wdi_country_df.columns}\")\n",
    "\n",
    "# wdi_series\n",
    "wdi_series_columns = wdi_series_df.columns\n",
    "\n",
    "for column in wdi_series_columns:\n",
    "  if column.__contains__(\" \"):\n",
    "    new_column_name = column.replace(\" \", \"_\")\n",
    "    wdi_series_df = wdi_series_df.withColumnRenamed(column, new_column_name)\n",
    "\n",
    "print(f\"Updated Column names:: {wdi_series_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records that only consist of null values (records with null values on all columns).\n",
    "\n",
    "year_columns = list(str(year) for year in range(1960, 2021))\n",
    "\n",
    "wdi_data_df = wdi_data_df.dropna(how=\"all\", subset=year_columns)\n",
    "wdi_country_df = wdi_country_df.dropna(how=\"all\")\n",
    "wdi_series_df = wdi_series_df.dropna(how=\"all\")\n",
    "\n",
    "print(f\"Wdi data with null dropped count:: {wdi_data_df.count()}\")\n",
    "print(f\"Wdi country with null dropped count:: {wdi_country_df.count()}\")\n",
    "print(f\"Wdi series with null dropped count:: {wdi_series_df.count()}\")\n",
    "\n",
    "# Drop duplicate records\n",
    "\n",
    "wdi_data = wdi_data_df.dropDuplicates()\n",
    "wdi_country = wdi_country_df.dropDuplicates()\n",
    "wdi_series = wdi_series_df.dropDuplicates()\n",
    "\n",
    "print(f\"Wdi data with duplicates dropped count:: {wdi_data_df.count()}\")\n",
    "print(f\"Wdi country with duplicates dropped count:: {wdi_country_df.count()}\")\n",
    "print(f\"Wdi series with duplicates dropped count:: {wdi_series_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the WDICountry.csv and WDIData.csv files\n",
    "# Drop all records that have a country code (column: Country_Code) with a size other than three\n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "wdi_country_df = wdi_country_df.filter(length(wdi_country.Country_Code) == 3)\n",
    "print(f\"wdi country with filtered country code:: {wdi_country_df.count()}\")\n",
    "wdi_data_df = wdi_data_df.filter(length(wdi_data_df.Country_Code) == 3)\n",
    "print(f\"wdi data with filtered country code:: {wdi_data_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For WDISeries.csv, drop all records that contain a space character (\" \") in the Series_Code column.\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "wdi_series_df = wdi_series_df.filter(~col(\"Series_Code\").contains(\" \"))\n",
    "print(f\"wdi series with filtered series code:: {wdi_series_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_data.createOrReplaceTempView(\"wdi_data_tempTable\")\n",
    "wdi_country.createOrReplaceTempView(\"wdi_country_tempTable\")\n",
    "wdi_series.createOrReplaceTempView(\"wdi_series_tempTable\")\n",
    "\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS curated\")\n",
    "\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS curated.world_development_indicators.data as select * from wdi_data_tempTable\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS curated.world_development_indicators.country as select * from wdi_country_tempTable\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS curated.world_development_indicators.series as select * from wdi_series_tempTable\")\n",
    "\n",
    "spark.catalog.dropTempView(\"wdi_data_tempTable\")\n",
    "spark.catalog.dropTempView(\"wdi_country_tempTable\")\n",
    "spark.catalog.dropTempView(\"wdi_series_tempTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
