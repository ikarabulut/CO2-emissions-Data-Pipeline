{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Iceberg Catalog Setup\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Running\")\n",
    "print(spark.sparkContext.getConf().getAll())\n",
    "print(\"current catalog:\", spark.catalog.currentCatalog())\n",
    "print(\"Spark UI:\", spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "emissions_data_path = \"/home/iceberg/data/emissions_data\"\n",
    "\n",
    "file_path = f\"{emissions_data_path}/co2_emissions_passenger_cars_2020.json\"\n",
    "file_name = Path(file_path).stem\n",
    "\n",
    "df = spark.read.option(\"multiline\",\"true\").json(file_path)\n",
    "df.createOrReplaceTempView(f\"{file_name}_tempTable\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS raw.co2_passenger_cars_emissions.{file_name} as select * from {file_name}_tempTable\")\n",
    "spark.catalog.dropTempView(f\"{file_name}_tempTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_emissions_2020_df = spark.read.table(\"raw.co2_passenger_cars_emissions.co2_emissions_passenger_cars_2020\")\n",
    "\n",
    "co2_emissions_2020_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# ------ Applying the data quality filters --------\n",
    "\n",
    "# Replace spaces in column names with underscores and remove ()\n",
    "co2_emissions_columns = co2_emissions_2020_df.columns\n",
    "print(f\"Original Column names:: {co2_emissions_2020_df.columns}\")\n",
    "\n",
    "co2_emissions_2020_df = (co2_emissions_2020_df.select(\n",
    "                      [F.col(col).alias(re.sub('[()]', '', col.replace(' ', '_'))) for col in co2_emissions_2020_df.columns]\n",
    "                    ))\n",
    "\n",
    "\n",
    "print(f\"Updated Column names:: {co2_emissions_2020_df.columns}\")\n",
    "\n",
    "# Drop null records\n",
    "print(f\"Number of records of CO2 emissions dataframe before dropping nulls: {co2_emissions_2020_df.count()}\")\n",
    "co2_emissions_2020_df = co2_emissions_2020_df.na.drop('all')\n",
    "print(f\"Number of records of CO2 emissions dataframe after dropping nulls: {co2_emissions_2020_df.count()}\")\n",
    "\n",
    "# Drop duplicates\n",
    "print(f\"Number of records of CO2 emissions dataframe before dropping duplicates: {co2_emissions_2020_df.count()}\")\n",
    "co2_emissions_2020_df = co2_emissions_2020_df.distinct()\n",
    "print(f\"Number of records of CO2 emissions dataframe after dropping duplicates: {co2_emissions_2020_df.count()}\")\n",
    "\n",
    "# Filter records with corrupt Member State code - We keep values with two uppercase letters\n",
    "print(f\"Number of records of CO2 emissions dataframe before MS filter: {co2_emissions_2020_df.count()}\")\n",
    "co2_emissions_2020_df = co2_emissions_2020_df.filter(co2_emissions_2020_df['MS'].rlike('^[A-Z][A-Z]$'))\n",
    "print(f\"Number of records of CO2 emissions dataframe after MS filter: {co2_emissions_2020_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the new column in the output (Enedc_g/km_V2)\n",
    "display(co2_emissions_2020_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType\n",
    "# We use repartition() to get one file per partition value\n",
    "# We're dropping the column z_Wh/km because it only contains null values for this year\n",
    "# Do the same to other columns that may cause issues, except the column Enedc_g/km_V2\n",
    "co2_emissions_2020_df = co2_emissions_2020_df.repartition('year')\n",
    "co2_emissions_2020_df = co2_emissions_2020_df.withColumn('z_Wh/km', F.col('z_Wh/km').cast(LongType()))\n",
    "(\n",
    "  co2_emissions_2020_df\n",
    "  .write\n",
    "  .mode('append')\n",
    "  .partitionBy('year')\n",
    "  .format('iceberg')\n",
    "  .saveAsTable('curated.co2_passenger_cars_emissions')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the columns to match business requirements\n",
    "co2_emissions_2020_df = (co2_emissions_2020_df\n",
    "                      .withColumnRenamed('Enedc_g/km', 'Enedc_g/km_deprecated')\n",
    "                      .withColumnRenamed('Enedc_g/km_V2', 'Enedc_g/km')\n",
    "                      )\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "  ALTER TABLE curated.co2_passenger_cars_emissions\n",
    "  ADD COLUMNS (`Enedc_g/km_deprecated` DOUBLE)\n",
    "\"\"\")\n",
    "\n",
    "(co2_emissions_2020_df\n",
    ".repartition(\"year\")\n",
    ".writeTo(\"curated.co2_passenger_cars_emissions\")\n",
    ".partitionedBy(\"year\")\n",
    ".options(format=\"iceberg\", mode=\"overwrite\", mergeSchema=\"true\")\n",
    ".createOrReplace()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the history of the table\n",
    "history_df = spark.read.format(\"iceberg\") \\\n",
    "    .load(\"curated.co2_passenger_cars_emissions.history\")\n",
    "\n",
    "# Show the results to display the history\n",
    "history_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
